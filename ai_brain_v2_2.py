# -*- coding: utf-8 -*-
"""
AI Brain v3.0 - Beast Mode (ì•¼ìˆ˜ ëª¨ë“œ)
- ğŸ”¥ í˜ë¥´ì†Œë‚˜ ë³€ê²½: ë³´ìˆ˜ì  ì „ëµê°€ â†’ ê³µê²©ì  ìŠ¤ìº˜í¼
- í”„ë¡¬í”„íŠ¸ ê°œì¡°: ì•ˆì •ì„± ë¬´ì‹œ, í…ë²„ê±° ê°€ëŠ¥ì„± í¬ì°©
- ê´€ë ¨ì£¼ ì°¾ê¸°: ì§ì ‘ ìˆ˜í˜œì£¼ ìš°ì„  (ëŒ€í˜•ì£¼ ë°°ì œ)
- Gemini 2.5 Flash ê³„ì—´ ì‚¬ìš© (ì‚¬ìš©ì ì œê³µ ëª¨ë¸ ëª©ë¡ ì¤€ìˆ˜)
"""

from google import genai
from google.genai import types
import logging
import json
import re
from config import Config

logger = logging.getLogger(__name__)

class AIBrainV3:
    def __init__(self):
        self.api_key = Config.GEMINI_API_KEY
        
        if not self.api_key:
            raise ValueError("âŒ GEMINI_API_KEY í•„ìˆ˜!")
        
        self.client = genai.Client(api_key=self.api_key)
        
        # ğŸ”¥ v3.0: ì‚¬ìš©ì ì œê³µ ëª¨ë¸ ëª©ë¡ ì‚¬ìš©
        # Gemini 2.5 Flash, Gemini 2.5 Flash Lite, Gemini 3 Flash
        self.scanner_models = [
            'gemini-2.5-flash',          # 1ìˆœìœ„
            'gemini-2.5-flash-lite',     # ë°±ì—…
            'gemini-3-flash'             # ë°±ì—… (Preview)
        ]
        
        self.report_models = [
            'gemini-3-flash',            # ê³ ì„±ëŠ¥
            'gemini-2.5-flash',          # ë°±ì—…
            'gemini-2.5-flash-lite'      # ë°±ì—…
        ]
        
        logger.info("ğŸº AI Brain v3.0 Beast Mode ì´ˆê¸°í™”")

    def _parse_json_safely(self, text):
        """
        AI ì‘ë‹µì—ì„œ JSON ë°ì´í„°ë§Œ ì •ë°€í•˜ê²Œ ì¶”ì¶œ
        """
        try:
            if not text:
                return None

            # 1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
            text = re.sub(r'```json\s*', '', text)
            text = re.sub(r'```\s*', '', text)
            
            # 2. ê°€ì¥ ì²˜ìŒ '{' ì™€ ê°€ì¥ ë§ˆì§€ë§‰ '}' ì°¾ê¸°
            start_idx = text.find('{')
            end_idx = text.rfind('}')
            
            if start_idx == -1 or end_idx == -1:
                return None
            
            # 3. ì •í™•íˆ JSON êµ¬ê°„ë§Œ ì˜ë¼ëƒ„
            json_str = text[start_idx : end_idx + 1]
            
            return json.loads(json_str)
        except Exception:
            return None
    
    async def quick_score(self, title, threshold=8.0):
        """
        ğŸ”¥ v3.0 Beast Mode: ë¹ ë¥¸ 1ì°¨ í•„í„° (ì œëª©ë§Œ)
        - ë³´ìˆ˜ì  ê´€ì  íê¸°
        - 8ì  ì´ìƒ: ìƒí•œê°€ ê°€ëŠ¥ì„± ìˆëŠ” í™•ì‹¤í•œ í˜¸ì¬
        """
        prompt = f"""
        ë„ˆëŠ” ì´ˆë‹¨íƒ€ ê¸‰ë“±ì£¼ ì „ë¬¸ ìŠ¤ìº˜í¼ë‹¤. ë‰´ìŠ¤ ì œëª©ë§Œ ë³´ê³  ìƒí•œê°€ ê°€ëŠ¥ì„±ì„ 0~10ì ìœ¼ë¡œ í‰ê°€í•´ë¼.
        
        ì œëª©: {title}
        
        í‰ê°€ ê¸°ì¤€:
        - 8~10ì : FDA ìŠ¹ì¸, M&A, ì •ë¶€ ê³„ì•½, ìµœëŒ€ì£¼ì£¼ ë³€ê²½, ê¸´ê¸‰ ê³µì‹œ ë“± í™•ì‹¤í•œ í˜¸ì¬
        - 5~7ì : ì„ìƒ ë°ì´í„°, íŒŒíŠ¸ë„ˆì‹­, ì‹¤ì  ì„œí”„ë¼ì´ì¦ˆ ë“± ì¤‘ê°„ í˜¸ì¬
        - 0~4ì : ì˜ê²¬, ì „ë§, ë¶„ì„, ë¦¬í¬íŠ¸ ë“± ì¡ë‹´
        
        âš ï¸ ì¤‘ìš”: ì•ˆì •ì„± ë”°ì§€ì§€ ë§ˆë¼. ê¸‰ë“± ê°€ëŠ¥ì„±ë§Œ íŒë‹¨í•´ë¼.
        
        JSON í˜•ì‹:
        {{"score": ìˆ«ì}}
        """
        
        for model in self.scanner_models:
            try:
                config = types.GenerateContentConfig(
                    response_mime_type='application/json',
                    temperature=0.3
                )
                
                response = await self.client.aio.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=config
                )
                
                result = self._parse_json_safely(response.text)
                
                if not result:
                    continue
                
                score = result.get('score', 0)
                return score >= threshold
                
            except Exception as e:
                logger.debug(f"[{model}] quick_score ì‹¤íŒ¨: {e}")
                continue
        
        return False
    
    async def analyze_news_signal(self, news_item):
        """
        ğŸ”¥ v3.0 Beast Mode: ìƒì„¸ ë‰´ìŠ¤ ë¶„ì„ + ì§ì ‘ ìˆ˜í˜œì£¼ ì°¾ê¸°
        - ëŒ€í˜•ì£¼(ì‚¼ì„±ì „ì, ì—”ë¹„ë””ì•„) ì¶”ì²œ ê¸ˆì§€
        - ì‹œì´ ì‘ì•„ë„ ì§ì ‘ì ì¸ ìˆ˜í˜œì£¼ë¥¼ ì°¾ì•„ë‚´ë¼
        - ë‰´ìŠ¤ì— ì¢…ëª©ëª…/í‹°ì»¤ ì–¸ê¸‰ ì‹œ ë¬´ì¡°ê±´ 1ìˆœìœ„
        """
        prompt = f"""
        ë„ˆëŠ” ì´ˆë‹¨íƒ€ ê¸‰ë“±ì£¼ ì „ë¬¸ ìŠ¤ìº˜í¼ë‹¤. ì´ ë‰´ìŠ¤ë¥¼ ë¶„ì„í•´ì„œ ì§ì ‘ ìˆ˜í˜œì£¼ë¥¼ ì°¾ì•„ì¤˜.
        
        ì œëª©: {news_item['title']}
        ì¶œì²˜: {news_item.get('source', 'Unknown')}
        
        ë¶„ì„ ìš”ì²­:
        1. ê¸‰ë“± ê°•ë„ 0~10ì  (8ì  ë¯¸ë§Œì€ ë¬´ì‹œ)
        2. í™•ì‹¤ì„±: "confirmed" (ìŠ¹ì¸/ê³„ì•½ ì™„ë£Œ) vs "uncertain" (ì˜ˆìƒ/ì „ë§)
        3. ì§ì ‘ ìˆ˜í˜œì£¼ 1ë“±, 2ë“±, 3ë“± (í‹°ì»¤, ê¸°ì—…ëª…, ì´ìœ )
        
        ğŸ”¥ í•µì‹¬ ë£°:
        - ë‰´ìŠ¤ì— ì¢…ëª©ëª…/í‹°ì»¤ê°€ ëª…ì‹œë˜ì–´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ê·¸ ì¢…ëª©ì„ 1ìˆœìœ„ë¡œ ì¡ì•„ë¼
        - ëŒ€í˜•ì£¼(ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤, ì—”ë¹„ë””ì•„, ì• í”Œ, ë§ˆì´í¬ë¡œì†Œí”„íŠ¸) ì¶”ì²œ ê¸ˆì§€
        - ì‹œì´ì´ ì‘ë”ë¼ë„ ì§ì ‘ ìˆ˜í˜œë¥¼ ë°›ëŠ” ì¢…ëª©ì„ ì°¾ì•„ë¼
        - ê´€ë ¨ì£¼ ì°¾ê¸°ê°€ ì–´ë µë‹¤ë©´ "UNKNOWN"ìœ¼ë¡œ í‘œì‹œí•´ë¼ (ì–µì§€ë¡œ ëŒ€í˜•ì£¼ ë„£ì§€ ë§ˆë¼)
        
        ì˜ˆì‹œ:
        - "RIME Announces Partnership with Nvidia" â†’ 1ë“±: RIME (ì£¼ì¸ê³µ), 2ë“±: ë¬¼ë¥˜/AI ê´€ë ¨ì£¼
        - "ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤, FDA ìŠ¹ì¸" â†’ 1ë“±: ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤ (ì£¼ì¸ê³µ)
        - "ë°˜ë„ì²´ ì‚°ì—… ì „ë§ ê¸ì •ì " â†’ UNKNOWN (ë‰´ìŠ¤ê°€ ì• ë§¤í•¨)
        
        JSON í˜•ì‹:
        {{
            "score": 0~10,
            "certainty": "confirmed" or "uncertain",
            "summary": "í•µì‹¬ ìš”ì•½ 1ì¤„",
            "key_catalyst": "í•µì‹¬ ì¬ë£Œ",
            "ticker_in_news": "ë‰´ìŠ¤ì— ëª…ì‹œëœ ì¢…ëª©ëª…/í‹°ì»¤ (ì—†ìœ¼ë©´ null)",
            "recommendations": [
                {{
                    "rank": "1ë“± (ëŒ€ì¥ì£¼)",
                    "ticker": "ì¢…ëª©ì½”ë“œ",
                    "name": "íšŒì‚¬ëª…",
                    "reason": "ìˆ˜í˜œ ì´ìœ "
                }},
                {{
                    "rank": "2ë“±",
                    "ticker": "ì¢…ëª©ì½”ë“œ",
                    "name": "íšŒì‚¬ëª…",
                    "reason": "ìˆ˜í˜œ ì´ìœ "
                }},
                {{
                    "rank": "3ë“±",
                    "ticker": "ì¢…ëª©ì½”ë“œ",
                    "name": "íšŒì‚¬ëª…",
                    "reason": "ìˆ˜í˜œ ì´ìœ "
                }}
            ],
            "risk_factors": ["ë¦¬ìŠ¤í¬ 1", "ë¦¬ìŠ¤í¬ 2"]
        }}
        
        âš ï¸ ë‹¤ì‹œ ê°•ì¡°: ë‰´ìŠ¤ì— ì¢…ëª©ì´ ëª…ì‹œë˜ì–´ ìˆë‹¤ë©´ ë¬´ì¡°ê±´ ê·¸ ì¢…ëª©ì„ 1ìˆœìœ„ë¡œ!
        """
        
        for model in self.report_models:
            try:
                config = types.GenerateContentConfig(
                    response_mime_type='application/json',
                    temperature=0.4
                )
                
                response = await self.client.aio.models.generate_content(
                    model=model,
                    contents=prompt,
                    config=config
                )
                
                result = self._parse_json_safely(response.text)
                
                if not result:
                    continue
                
                # ê²€ì¦
                score = result.get('score', 0)
                if score < 7:
                    return None
                
                return result
                
            except Exception as e:
                logger.debug(f"[{model}] analyze_news_signal ì‹¤íŒ¨: {e}")
                continue
        
        return None
    
    async def generate_daily_summary(self, signals):
        """
        ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸
        """
        if not signals:
            return "ğŸº ì˜¤ëŠ˜ì€ ì‚¬ëƒ¥ê°ì´ ì—†ìŠµë‹ˆë‹¤. ë‚´ì¼ì„ ê¸°ì•½í•©ë‹ˆë‹¤."
        
        top_signals = signals[:5]
        
        prompt = f"""
        ë„ˆëŠ” ì´ˆë‹¨íƒ€ ê¸‰ë“±ì£¼ ì „ë¬¸ ìŠ¤ìº˜í¼ë‹¤. ì˜¤ëŠ˜ì˜ í•µì‹¬ ì´ìŠˆë¥¼ ìš”ì•½í•´ì¤˜.
        
        ì£¼ìš” ì‹œê·¸ë„:
        {json.dumps(top_signals, ensure_ascii=False, indent=2)}
        
        ìš”ì•½ í˜•ì‹:
        1. ì˜¤ëŠ˜ì˜ í•µì‹¬ í…Œë§ˆ (2~3ì¤„)
        2. ì£¼ëª©í•  ì¢…ëª© TOP 3 (ì¢…ëª©ëª… + ì´ìœ )
        3. ë¦¬ìŠ¤í¬ ìš”ì¸
        
        âš ï¸ ìŠ¤íƒ€ì¼: ê°„ê²°í•˜ê³  ê³µê²©ì ìœ¼ë¡œ (ìƒí•œê°€ ì˜ˆì¸¡ì€ í”¼í•˜ë˜, ê¸‰ë“± ê°€ëŠ¥ì„±ì€ ì–¸ê¸‰)
        """
        
        for model in self.report_models:
            try:
                response = await self.client.aio.models.generate_content(
                    model=model,
                    contents=prompt
                )
                
                return response.text
                
            except Exception as e:
                logger.debug(f"[{model}] generate_daily_summary ì‹¤íŒ¨: {e}")
                continue
        
        return "ğŸº ìš”ì•½ ìƒì„± ì‹¤íŒ¨"
