# -*- coding: utf-8 -*-
"""
Predictor Engine v2.2 - ì™„ì „ì²´
- DART API (í•œêµ­ ê³µì‹œ)
- SEC Form 4 (ë¯¸êµ­ ë‚´ë¶€ì)
- SEC 13D/13G (ê³ ë˜ ì¶”ì )
- ì¤‘ë³µ ë°©ì§€ ì™„ë²½
"""

import asyncio
import logging
from datetime import datetime, timedelta
import aiohttp
from bs4 import BeautifulSoup
import re
import urllib.parse
import yfinance as yf
from config import Config

logger = logging.getLogger(__name__)

class PredictorEngineV2_2:
    def __init__(self):
        # DART API (í•œêµ­)
        self.dart_api_url = "https://opendart.fss.or.kr/api/list.xml"
        self.dart_api_key = Config.DART_API_KEY
        
        # SEC (ë¯¸êµ­)
        self.sec_form4_url = "https://www.sec.gov/cgi-bin/browse-edgar"
        self.sec_13d_url = "https://www.sec.gov/cgi-bin/browse-edgar"
        self.sec_company_tickers = "https://www.sec.gov/files/company_tickers.json"
        
        # ì¤‘ë³µ ë°©ì§€
        self.seen_dart = set()
        self.seen_form4 = set()
        self.seen_13d = set()
        
        # CIK â†’ í‹°ì»¤ ë§¤í•‘
        self.cik_to_ticker = {}
        self.code_cache = {}
        
        # ìœ ëª… íˆ¬ìì (í•œêµ­)
        self.famous_kr_whales = {
            'êµ­ë¯¼ì—°ê¸ˆ': 'ğŸ‹ êµ­ë¯¼ì—°ê¸ˆê³µë‹¨',
            'ë¯¸ë˜ì—ì…‹': 'ğŸ‹ ë¯¸ë˜ì—ì…‹ìì‚°ìš´ìš©',
            'ì‚¼ì„±ìƒëª…': 'ğŸ‹ ì‚¼ì„±ìƒëª…ë³´í—˜',
            'KBìì‚°': 'ğŸ‹ KBìì‚°ìš´ìš©',
            'í•œêµ­íˆ¬ì': 'ğŸ‹ í•œêµ­íˆ¬ìì‹ íƒ',
        }
        
        # ìœ ëª… ê³ ë˜ (ë¯¸êµ­) - 40ëª…
        self.famous_us_whales = {
            'ICAHN': 'ğŸ‘‘ Carl Icahn',
            'ACKMAN': 'ğŸ‘‘ Bill Ackman (Pershing)',
            'EINHORN': 'ğŸ‘‘ David Einhorn',
            'BERKSHIRE': 'ğŸ† Warren Buffett',
            'GATES': 'ğŸ† Bill Gates',
            'SOROS': 'ğŸ† George Soros',
            'STARBOARD': 'âš”ï¸ Starboard Value',
            'ELLIOTT': 'âš”ï¸ Elliott Management',
            'THIRD POINT': 'âš”ï¸ Third Point',
            'PERSHING': 'âš”ï¸ Pershing Square',
            'VALUEACT': 'âš”ï¸ ValueAct',
            'JANA': 'âš”ï¸ JANA Partners',
            'BLACKROCK': 'ğŸ¦ BlackRock',
            'VANGUARD': 'ğŸ¦ Vanguard',
            'STATE STREET': 'ğŸ¦ State Street',
            'FIDELITY': 'ğŸ¦ Fidelity',
            'GOLDMAN': 'ğŸ¦ Goldman Sachs',
            'GOLDMAN SACHS': 'ğŸ¦ Goldman Sachs',
            'MORGAN STANLEY': 'ğŸ¦ Morgan Stanley',
            'JP MORGAN': 'ğŸ¦ JP Morgan',
            'JPMORGAN': 'ğŸ¦ JP Morgan',
            'CITADEL': 'ğŸ¤– Citadel',
            'RENAISSANCE': 'ğŸ¤– Renaissance Tech',
            'BRIDGEWATER': 'ğŸ¤– Bridgewater',
            'TWO SIGMA': 'ğŸ¤– Two Sigma',
            'DE SHAW': 'ğŸ¤– D.E. Shaw',
            'MILLENNIUM': 'ğŸ¤– Millennium',
            'SOFTBANK': 'ğŸ‡¯ğŸ‡µ SoftBank (ì†ì •ì˜)',
            'BAUPOST': 'ğŸ’ Baupost',
            'APPALOOSA': 'ğŸ’ Appaloosa',
            'GREENLIGHT': 'ğŸ’ Greenlight',
            'LONE PINE': 'ğŸ’ Lone Pine',
        }
        
        logger.info("ğŸ”® Predictor Engine v2.2 ì´ˆê¸°í™”")
    
    async def generate_daily_report(self, market='KR'):
        """
        ì•„ì¹¨/ì €ë… ë¦¬í¬íŠ¸
        """
        today = datetime.now().date()
        
        report = {
            'date': today,
            'market': market,
            'hot_stocks': [],
            'events_today': [],
            'risks': []
        }
        
        if market == 'KR':
            # DART ê³µì‹œ
            dart_signals = await self.scan_dart_filings(days=3)
            if dart_signals:
                report['hot_stocks'].extend(dart_signals)
                
                insider_count = sum(1 for s in dart_signals if s['signal_type'] == 'insider_buy')
                ownership_count = sum(1 for s in dart_signals if s['signal_type'] == 'ownership_increase')
                
                if insider_count > 0:
                    report['events_today'].append(f"ë‚´ë¶€ì ë§¤ìˆ˜: {insider_count}ê±´")
                if ownership_count > 0:
                    report['events_today'].append(f"ì§€ë¶„ ê³µì‹œ: {ownership_count}ê±´")
        
        else:  # US
            # SEC Form 4
            form4_signals = await self.scan_sec_form4(hours=24)
            if form4_signals:
                report['hot_stocks'].extend(form4_signals)
                report['events_today'].append(f"ë‚´ë¶€ì ë§¤ìˆ˜: {len(form4_signals)}ê±´")
            
            # SEC 13D/13G (ê³ ë˜)
            whale_signals = await self.scan_sec_13d(hours=24)
            if whale_signals:
                report['hot_stocks'].extend(whale_signals)
                report['events_today'].append(f"ê³ ë˜ ì§€ë¶„ ê³µì‹œ: {len(whale_signals)}ê±´")
        
        # ì¤‘ë³µ ì œê±°
        report['hot_stocks'] = self._deduplicate_and_rank(report['hot_stocks'])
        
        # ë¦¬ìŠ¤í¬ ì²´í¬
        report['risks'] = await self.check_market_risks(market)
        
        return report
    
    async def scan_dart_filings(self, days=3):
        """í•œêµ­ DART ê³µì‹œ (ê¸°ì¡´ ê²€ì¦ë¨ + ê¸‰ë“±ì£¼ ë¡œì§ ê°•í™”)"""
        signals = []
        
        if not self.dart_api_key or len(self.dart_api_key) < 10:
            logger.warning("âš ï¸ DART API í‚¤ ì—†ìŒ")
            return signals
        
        try:
            params = {
                'crtfc_key': self.dart_api_key,
                'page_no': '1',
                'page_count': '50'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(self.dart_api_url, params=params, timeout=10) as response:
                    if response.status != 200:
                        return signals
                    
                    xml = await response.text()
                    soup = BeautifulSoup(xml, 'xml')
                    
                    status = soup.find('status')
                    if status and status.text != '000':
                        return signals
                    
                    items = soup.find_all('list')
                    
                    for item in items:
                        try:
                            corp_name = item.find('corp_name').text
                            report_nm = item.find('report_nm').text
                            rcept_no = item.find('rcept_no').text
                            rcept_dt = item.find('rcept_dt').text
                            
                            if rcept_no in self.seen_dart:
                                continue
                            
                            filing_date = datetime.strptime(rcept_dt, '%Y%m%d').date()
                            if filing_date < (datetime.now().date() - timedelta(days=days)):
                                continue
                            
                            # ê³µì‹œ ë¶„ë¥˜
                            signal_type = None
                            confidence = 0.5
                            expected_impact = ''
                            is_negative = False
                            
                            if 'ì„ì›' in report_nm or 'ì£¼ìš”ì£¼ì£¼íŠ¹ì •ì¦ê¶Œ' in report_nm:
                                signal_type = 'insider_buy'
                                confidence = 0.75
                                expected_impact = '+10~30%'
                                reason = 'ğŸ‘” ë‚´ë¶€ì ë§¤ìˆ˜'
                            elif 'ëŒ€ëŸ‰ë³´ìœ ' in report_nm:
                                signal_type = 'ownership_increase'
                                confidence = 0.80
                                expected_impact = '+15~40%'
                                reason = 'ğŸ‹ ëŒ€ëŸ‰ë³´ìœ  ì‹ ê³  (5%+)'
                            elif 'ë‹¨ì¼íŒë§¤' in report_nm or 'ê³µê¸‰ê³„ì•½' in report_nm:
                                signal_type = 'contract'
                                confidence = 0.70
                                expected_impact = '+10~25%'
                                reason = 'ğŸ“œ ëŒ€ê·œëª¨ ê³„ì•½'
                            
                            # ğŸ”¥ [NEW] ì‹¤ì  ëŒ€ë°• ê³µì‹œ (ì—ìŠ¤ì½”ë„¥/ë‰´ì¸í… ì‚¬ë¡€)
                            elif 'ë§¤ì¶œì•¡' in report_nm or 'ì†ìµêµ¬ì¡°' in report_nm:
                                signal_type = 'earnings_surprise'
                                confidence = 0.85
                                expected_impact = '+15~30%'
                                reason = 'ğŸ’° ì‹¤ì  ëŒ€ë°• (ì†ìµêµ¬ì¡° ë³€ë™)'
                            elif 'ì ì •ì‹¤ì ' in report_nm:
                                signal_type = 'earnings_provisional'
                                confidence = 0.80
                                expected_impact = '+10~20%'
                                reason = 'ğŸ“Š ì ì • ì‹¤ì  ë°œí‘œ'
                                
                            elif 'ì£¼ì‹êµí™˜' in report_nm or 'í•©ë³‘' in report_nm:
                                signal_type = 'merger'
                                confidence = 0.85
                                expected_impact = '+20~50%'
                                reason = 'ğŸ¤ M&A ê³µì‹œ'
                            elif 'ë¬´ìƒì¦ì' in report_nm:
                                signal_type = 'bonus_issue'
                                confidence = 0.75
                                expected_impact = '+10~30%'
                                reason = 'ğŸ ë¬´ìƒì¦ì'
                            elif 'ê³µê°œë§¤ìˆ˜' in report_nm:
                                signal_type = 'tender_offer'
                                confidence = 0.90
                                expected_impact = '+25~60%'
                                reason = 'ğŸ’° ê³µê°œë§¤ìˆ˜'
                            
                            # ğŸ”¥ [NEW] ìœ ìƒì¦ì ì •ë°€ ë¶„ì„ (ì¼€ì´ë°”ì´ì˜¤ ì‚¬ë¡€)
                            elif 'ìœ ìƒì¦ì' in report_nm:
                                if 'ì œ3ìë°°ì •' in report_nm or '3ìë°°ì •' in report_nm:
                                    # 3ìë°°ì •ì€ í˜¸ì¬! (í°ì† ìœ ì…)
                                    signal_type = '3rd_party_allocation'
                                    confidence = 0.85
                                    expected_impact = '+15~30% (ìƒí•œê°€ í›„ë³´)'
                                    reason = 'ğŸš€ ì œ3ìë°°ì • ìœ ìƒì¦ì (ì‹ ê·œ ìê¸ˆ/ì£¼ì£¼)'
                                    is_negative = False
                                else:
                                    # ì¼ë°˜ ì£¼ì£¼ë°°ì •ì€ ì•…ì¬
                                    signal_type = 'dilution'
                                    is_negative = True
                                    reason = 'âš ï¸ ì£¼ì£¼ë°°ì • ìœ ìƒì¦ì (ì£¼ê°€ í¬ì„)'

                            # ğŸ”¥ [NEW] ìµœëŒ€ì£¼ì£¼ ë³€ê²½ (í”Œë£¨í† ìŠ¤ ì‚¬ë¡€)
                            elif 'ìµœëŒ€ì£¼ì£¼ë³€ê²½' in report_nm or 'ì£¼ì‹ì–‘ìˆ˜ë„' in report_nm:
                                signal_type = 'ownership_change'
                                confidence = 0.90
                                expected_impact = '+20~30% (ê²½ì˜ê¶Œ í”„ë¦¬ë¯¸ì—„)'
                                reason = 'ğŸ‘‘ ìµœëŒ€ì£¼ì£¼ ë³€ê²½ (ê²½ì˜ê¶Œ ë§¤ê°)'

                            elif 'ì „í™˜ì‚¬ì±„' in report_nm or 'CB' in report_nm:
                                signal_type = 'cb_issue'
                                is_negative = True
                                reason = 'âš ï¸ CB ë°œí–‰'
                            elif 'ê°ì' in report_nm:
                                signal_type = 'reverse_split'
                                is_negative = True
                                reason = 'ğŸš¨ ê°ì (ê·¹ì•…ì¬)'
                            else:
                                continue
                            
                            # ì¢…ëª© ì½”ë“œ ë§¤í•‘
                            stock_code = await self._get_stock_code_kr(corp_name, session)
                            ticker = stock_code if stock_code else "UNKNOWN"
                            
                            # ìœ ëª… íˆ¬ìì
                            whale_name = None
                            if not is_negative:
                                for whale_key, whale_desc in self.famous_kr_whales.items():
                                    if whale_key in corp_name:
                                        whale_name = whale_desc
                                        confidence = min(confidence + 0.1, 0.95)
                                        break
                            
                            self.seen_dart.add(rcept_no)
                            
                            filing_url = f"http://dart.fss.or.kr/dsaf001/main.do?rcpNo={rcept_no}"
                            
                            signals.append({
                                'ticker': ticker,
                                'name': corp_name,
                                'signal_type': signal_type,
                                'event_date': filing_date,
                                'confidence': confidence,
                                'expected_impact': expected_impact,
                                'reason': f"{whale_name}\n{reason}" if whale_name else reason,
                                'filing_id': rcept_no,  # ğŸ†• ì¤‘ë³µ ì²´í¬ìš©
                                'market': 'KR',  # ğŸ†• ì‹œì¥ êµ¬ë¶„
                                'details': {
                                    'report_name': report_nm,
                                    'filing_url': filing_url,
                                    'is_negative': is_negative
                                }
                            })
                            
                            logger.info(f"ğŸ“‹ DART: {corp_name} - {reason}")
                            
                        except Exception as e:
                            logger.debug(f"DART í•­ëª© ì˜¤ë¥˜: {e}")
                            continue
                    
                    if len(self.seen_dart) > 1000:
                        self.seen_dart.clear()
            
            logger.info(f"âœ… DART: {len(signals)}ê±´")
            return signals
            
        except Exception as e:
            logger.error(f"DART ì˜¤ë¥˜: {e}")
            return signals
    
    async def scan_sec_form4(self, hours=24):
        """ë¯¸êµ­ SEC Form 4 (ê¸°ì¡´ ê²€ì¦ë¨)"""
        signals = []
        
        try:
            params = {
                'action': 'getcurrent',
                'type': '4',
                'company': '',
                'dateb': '',
                'owner': 'include',
                'start': '0',
                'count': '100',
                'output': 'atom'
            }
            
            headers = {'User-Agent': 'Mozilla/5.0 (PredictorBot/2.2)'}
            
            async with aiohttp.ClientSession() as session:
                async with session.get(self.sec_form4_url, params=params, headers=headers, timeout=15) as response:
                    if response.status != 200:
                        return signals
                    
                    xml = await response.text()
                    soup = BeautifulSoup(xml, 'xml')
                    entries = soup.find_all('entry')[:40]
                    
                    for entry in entries:
                        try:
                            title = entry.find('title').text
                            link = entry.find('link')['href']
                            updated = entry.find('updated').text
                            
                            if link in self.seen_form4:
                                continue
                            
                            filing_time = datetime.fromisoformat(updated.replace('Z', '+00:00'))
                            now = datetime.now(filing_time.tzinfo)
                            
                            if (now - filing_time).total_seconds() > hours * 3600:
                                continue
                            
                            ticker_match = re.search(r'\(([A-Z]{1,5})\)', title)
                            if not ticker_match:
                                continue
                            
                            ticker = ticker_match.group(1)
                            
                            # ë§¤ìˆ˜/ë§¤ë„ êµ¬ë¶„
                            transaction_type = await self._parse_form4_type(link, session)
                            
                            if transaction_type != 'BUY':
                                continue
                            
                            self.seen_form4.add(link)
                            
                            signals.append({
                                'ticker': ticker,
                                'name': ticker,
                                'signal_type': 'insider_buy',
                                'event_date': filing_time.date(),
                                'confidence': 0.80,
                                'expected_impact': '+10~30%',
                                'reason': 'ğŸ‘” ì„ì› ë§¤ìˆ˜ (Form 4)',
                                'filing_id': link,  # ğŸ†• ì¤‘ë³µ ì²´í¬ìš©
                                'market': 'US',  # ğŸ†• ì‹œì¥ êµ¬ë¶„
                                'details': {
                                    'filing_url': link,
                                    'transaction_type': transaction_type
                                }
                            })
                            
                            logger.info(f"ğŸ‘” Form 4: {ticker} ë§¤ìˆ˜")
                            
                        except Exception as e:
                            logger.debug(f"Form 4 ì˜¤ë¥˜: {e}")
                            continue
                    
                    if len(self.seen_form4) > 500:
                        self.seen_form4.clear()
            
            logger.info(f"âœ… Form 4: {len(signals)}ê±´")
            return signals
            
        except Exception as e:
            logger.error(f"Form 4 ì˜¤ë¥˜: {e}")
            return signals
    
    async def scan_sec_13d(self, hours=24):
        """ë¯¸êµ­ SEC 13D/13G (ê³ ë˜ ì¶”ì )"""
        signals = []
        
        try:
            # CIK ë§¤í•‘ ë¡œë“œ (ìµœì´ˆ 1íšŒ)
            if not self.cik_to_ticker:
                await self._load_sec_mappings()
            
            params = {
                'action': 'getcurrent',
                'type': '',
                'company': '',
                'dateb': '',
                'owner': 'include',
                'start': '0',
                'count': '100',
                'output': 'atom'
            }
            
            headers = {
                'User-Agent': 'StockAlertBot admin@stockbot.com',
                'Accept-Encoding': 'gzip, deflate',
                'Host': 'www.sec.gov'
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.get(self.sec_13d_url, params=params, headers=headers, timeout=20) as response:
                    if response.status != 200:
                        return signals
                    
                    xml = await response.text()
                    soup = BeautifulSoup(xml, 'xml')
                    entries = soup.find_all('entry')[:50]
                    
                    for entry in entries:
                        try:
                            title = entry.find('title').text
                            link = entry.find('link')['href']
                            updated = entry.find('updated').text
                            
                            summary_tag = entry.find('summary')
                            summary = summary_tag.text if summary_tag else ''
                            
                            if link in self.seen_13d:
                                continue
                            
                            try:
                                filing_time = datetime.fromisoformat(updated.replace('Z', '+00:00'))
                            except:
                                filing_time = datetime.now()
                            
                            now = datetime.now(filing_time.tzinfo if filing_time.tzinfo else None)
                            if (now - filing_time).total_seconds() > hours * 3600:
                                continue
                            
                            # 13D/13G í•„í„°
                            form_type = None
                            priority = 0
                            
                            upper_title = title.upper()
                            
                            if "SC 13D/A" in upper_title:
                                form_type = "ğŸ”¥ SC 13D/A (ì§€ë¶„ ë³€ê²½)"
                                priority = 9
                            elif "SC 13D" in upper_title:
                                form_type = "ğŸš¨ SC 13D (5%+ ê³µê²©ì  íˆ¬ì)"
                                priority = 10
                            elif "SC 13G/A" in upper_title:
                                form_type = "ğŸ“ˆ SC 13G/A (ì§€ë¶„ ë³€ê²½)"
                                priority = 6
                            elif "SC 13G" in upper_title:
                                form_type = "ğŸ“Š SC 13G (5%+ ë‹¨ìˆœ íˆ¬ì)"
                                priority = 7
                            else:
                                continue
                            
                            # í‹°ì»¤ ì¶”ì¶œ
                            ticker = await self._extract_ticker_multi(title, summary, link, session)
                            final_symbol = ticker if ticker else "UNKNOWN"
                            
                            # ê³ ë˜ í™•ì¸
                            whale_name = None
                            for whale_key, whale_desc in self.famous_us_whales.items():
                                if whale_key in title.upper() or whale_key in summary.upper():
                                    whale_name = whale_desc
                                    priority += 3
                                    break
                            
                            self.seen_13d.add(link)
                            
                            trigger_msg = form_type
                            if whale_name:
                                trigger_msg = f"{whale_name}\n{form_type}"
                            
                            signals.append({
                                'ticker': final_symbol,
                                'name': final_symbol,
                                'signal_type': 'whale_alert',
                                'event_date': filing_time.date(),
                                'confidence': 0.85,
                                'expected_impact': '+15~50%',
                                'reason': trigger_msg,
                                'filing_id': link,  # ğŸ†• ì¤‘ë³µ ì²´í¬ìš©
                                'market': 'US',  # ğŸ†• ì‹œì¥ êµ¬ë¶„
                                'details': {
                                    'filing_url': link,
                                    'whale_name': whale_name,
                                    'form_type': form_type
                                }
                            })
                            
                            logger.info(f"ğŸ‹ 13D: {final_symbol} - {form_type}")
                            
                        except Exception as e:
                            logger.debug(f"13D ì˜¤ë¥˜: {e}")
                            continue
                    
                    if len(self.seen_13d) > 1000:
                        self.seen_13d.clear()
            
            logger.info(f"âœ… 13D/13G: {len(signals)}ê±´")
            return signals
            
        except Exception as e:
            logger.error(f"13D/13G ì˜¤ë¥˜: {e}")
            return signals
    
    async def _load_sec_mappings(self):
        """SEC CIK â†’ í‹°ì»¤ ë§¤í•‘"""
        try:
            headers = {'User-Agent': 'StockAlertBot admin@stockbot.com'}
            
            async with aiohttp.ClientSession() as session:
                async with session.get(self.sec_company_tickers, headers=headers, timeout=15) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        for company in data.values():
                            cik = str(company['cik_str']).zfill(10)
                            ticker = company['ticker']
                            self.cik_to_ticker[cik] = ticker
                        
                        logger.info(f"âœ… SEC ë§¤í•‘: {len(self.cik_to_ticker)}ê°œ")
                    
        except Exception as e:
            logger.error(f"SEC ë§¤í•‘ ì˜¤ë¥˜: {e}")
    
    async def _extract_ticker_multi(self, title, summary, link, session):
        """ë‹¤ì¤‘ ì „ëµ í‹°ì»¤ ì¶”ì¶œ"""
        # ì „ëµ 1: CIK
        cik_match = re.search(r'\((\d{10})\)', title)
        if not cik_match:
            cik_match = re.search(r'\((\d{7,10})\)', title)
        
        if cik_match:
            cik = cik_match.group(1).zfill(10)
            ticker = self.cik_to_ticker.get(cik)
            if ticker:
                return ticker
        
        # ì „ëµ 2: URL CIK
        if link:
            url_cik_match = re.search(r'/data/(\d+)/', link)
            if url_cik_match:
                cik = url_cik_match.group(1).zfill(10)
                ticker = self.cik_to_ticker.get(cik)
                if ticker:
                    return ticker
        
        # ì „ëµ 3: ê´„í˜¸ í‹°ì»¤
        ticker_match = re.search(r'\(([A-Z]{1,5})\)', title)
        if ticker_match:
            return ticker_match.group(1)
        
        return None
    
    async def _get_stock_code_kr(self, company_name, session):
        """í•œêµ­ ì¢…ëª© ì½”ë“œ"""
        if company_name in self.code_cache:
            return self.code_cache[company_name]
        
        try:
            encoded = urllib.parse.quote(company_name)
            url = f"https://finance.naver.com/search/searchList.naver?query={encoded}"
            
            async with session.get(url, timeout=5) as response:
                if response.status != 200:
                    return None
                
                html = await response.text()
                soup = BeautifulSoup(html, 'html.parser')
                
                result = soup.select_one('table.tbl_search tr td.tit a')
                if not result:
                    return None
                
                href = result.get('href', '')
                code_match = re.search(r'code=(\d{6})', href)
                
                if code_match:
                    code = code_match.group(1)
                    self.code_cache[company_name] = code
                    return code
        except:
            pass
        
        return None
    
    async def _parse_form4_type(self, filing_url, session):
        """Form 4 ë§¤ìˆ˜/ë§¤ë„ êµ¬ë¶„"""
        try:
            async with session.get(filing_url, timeout=5) as response:
                if response.status != 200:
                    return 'UNKNOWN'
                
                xml_text = await response.text()
                
                if '<transactionCode>P</transactionCode>' in xml_text:
                    return 'BUY'
                elif '<transactionCode>S</transactionCode>' in xml_text:
                    return 'SELL'
                else:
                    return 'UNKNOWN'
        except:
            return 'UNKNOWN'
    
    async def check_market_risks(self, market):
        """ë¦¬ìŠ¤í¬ ì²´í¬"""
        risks = []
        
        try:
            if market == 'US':
                vix = yf.Ticker('^VIX')
                vix_hist = vix.history(period='1d')
                
                if not vix_hist.empty:
                    vix_value = vix_hist['Close'].iloc[-1]
                    if vix_value > 30:
                        risks.append(f"âš ï¸ VIX ê³ ê³µí–‰ì§„ ({vix_value:.1f})")
                    elif vix_value > 20:
                        risks.append(f"ğŸ“Š VIX ìƒìŠ¹ ({vix_value:.1f})")
                
                sp500 = yf.Ticker('^GSPC')
                sp_hist = sp500.history(period='5d')
                
                if len(sp_hist) >= 2:
                    change = ((sp_hist['Close'].iloc[-1] - sp_hist['Close'].iloc[-2]) / sp_hist['Close'].iloc[-2]) * 100
                    if change < -2:
                        risks.append(f"ğŸ”´ S&P 500 ê¸‰ë½ ({change:.1f}%)")
            
            elif market == 'KR':
                kospi = yf.Ticker('^KS11')
                kospi_hist = kospi.history(period='5d')
                
                if len(kospi_hist) >= 2:
                    change = ((kospi_hist['Close'].iloc[-1] - kospi_hist['Close'].iloc[-2]) / kospi_hist['Close'].iloc[-2]) * 100
                    if change < -2:
                        risks.append(f"ğŸ”´ KOSPI ê¸‰ë½ ({change:.1f}%)")
        
        except Exception as e:
            logger.debug(f"ë¦¬ìŠ¤í¬ ì²´í¬ ì˜¤ë¥˜: {e}")
        
        return risks
    
    def _deduplicate_and_rank(self, signals):
        """
        ì¤‘ë³µ ì œê±° & ìˆœìœ„ - ìˆ˜ì • (ì œë¯¸ë‚˜ì´ ê²€ì¦)
        
        í•µì‹¬: "íšŒì‚¬ ì´ë¦„ì´ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ ë†ˆì´ë‹¤!"
        - UNKNOWN í‹°ì»¤ë„ íšŒì‚¬ëª…ìœ¼ë¡œ êµ¬ë¶„
        - ì§„ì§œ ê°™ì€ íšŒì‚¬ì˜ ì—¬ëŸ¬ ê³µì‹œë§Œ í•©ì¹¨
        """
        unique_map = {}
        
        for signal in signals:
            ticker = signal.get('ticker', 'UNKNOWN')
            name = signal.get('name', 'Unknown')
            filing_id = signal.get('filing_id', '')
            
            # ğŸ”¥ í•µì‹¬ ë¡œì§: UNKNOWNì´ë©´ íšŒì‚¬ëª…ìœ¼ë¡œ êµ¬ë¶„!
            if ticker == 'UNKNOWN' or not ticker:
                unique_key = f"UNKNOWN_{name}"
            else:
                unique_key = ticker
            
            # ê³ ìœ  ID = unique_key + filing_id
            # (ê°™ì€ íšŒì‚¬ì˜ ì„œë¡œ ë‹¤ë¥¸ ê³µì‹œëŠ” ë¶„ë¦¬)
            signal_id = f"{unique_key}_{filing_id}"
            
            # ì§„ì§œ ì¤‘ë³µ(=ê°™ì€ ê³µì‹œ)ë§Œ ì œì™¸
            if signal_id not in unique_map:
                unique_map[signal_id] = signal
            # ê°™ì€ signal_idë©´ ê±´ë„ˆëœ€ (ì´ë¯¸ ì¶”ê°€ë¨)
        
        # ì‹ ë¢°ë„ ìˆœ ì •ë ¬
        ranked = sorted(
            unique_map.values(),
            key=lambda x: x.get('confidence', 0),
            reverse=True
        )
        
        return ranked[:10]  # TOP 10
